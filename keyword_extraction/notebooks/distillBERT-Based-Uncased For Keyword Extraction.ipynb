{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"distillBERT-Based-Uncased For Keyword Extraction.ipynb","provenance":[],"collapsed_sections":["4CI0y8z9drX2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"65QMVGOsGaGn"},"source":["# distilbert-base-uncased"]},{"cell_type":"markdown","metadata":{"id":"5nmTM4ckx8Th"},"source":["# Install Libraries"]},{"cell_type":"code","metadata":{"id":"6UlU3zMX6TW-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901961778,"user_tz":-420,"elapsed":4128,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"138e4a29-a522-4816-d2bb-21ca8c94b60b"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"2oQ-ovttqKlR"},"source":["# Import Library"]},{"cell_type":"code","metadata":{"id":"4h51ZnKHqOlK","executionInfo":{"status":"ok","timestamp":1636901965859,"user_tz":-420,"elapsed":4085,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["import json\n","import copy\n","import time\n","import torch\n","import random\n","import datetime\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from os import listdir, path\n","import tensorflow as tf\n","from xml.dom import minidom\n","from os.path import isfile, join\n","from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertConfig, BertTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, AdamW, get_linear_schedule_with_warmup"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hokil_dM5tu-"},"source":["# 1. Setup"]},{"cell_type":"markdown","metadata":{"id":"4EVPZHjL6CqB"},"source":["## 1.1. Using Colab GPU for Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRU_-84i5nyD","executionInfo":{"status":"ok","timestamp":1636901968700,"user_tz":-420,"elapsed":2849,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"2ff4645a-8ef6-4201-d35e-07d78363d119"},"source":["# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"zs9lnolW6KlR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968700,"user_tz":-420,"elapsed":39,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"4e40d2d3-43f5-4589-db70-54e6ca28dc65"},"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"]}]},{"cell_type":"markdown","metadata":{"id":"3fKq--eS6XVx"},"source":["# 2. Loading KP Dataset"]},{"cell_type":"code","metadata":{"id":"COeTKdXfiV5j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968702,"user_tz":-420,"elapsed":36,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"3ed5fbaf-84e2-40aa-c894-0ee888b6a853"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"dFHPO3OiglCb"},"source":["## 2.1. Get All Filenames"]},{"cell_type":"code","metadata":{"id":"80yoH5p36Tak","executionInfo":{"status":"ok","timestamp":1636901968702,"user_tz":-420,"elapsed":34,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["root = \"drive/MyDrive/NLP/Tugas Akhir/keyword extraction resources/\"\n","saved_dataset_path = \"drive/MyDrive/NLP/Tugas Akhir/keyword extraction resources/saved_dataset/\""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFayvRnbzYdr","executionInfo":{"status":"ok","timestamp":1636901968703,"user_tz":-420,"elapsed":34,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# testarr = [1,2,3,4,5]\n","# with open(saved_dataset_path + 'testarr', 'wb') as f:\n","#     pickle.dump(testarr, f)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3YSPMFUzqcP","executionInfo":{"status":"ok","timestamp":1636901968703,"user_tz":-420,"elapsed":34,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# with open(saved_dataset_path + 'testarr', 'rb') as f:\n","#     testtesttest = pickle.load(f)\n","# testtesttest"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"rWi8m9DJg7Vm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968703,"user_tz":-420,"elapsed":33,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"2ae767a5-b830-465c-f00d-078964fbff41"},"source":["if not path.isfile(saved_dataset_path + 'dataset_filenames'):\n","  dataset_path = \"drive/MyDrive/NLP/Tugas Akhir/keyword extraction resources/dataset/train\"\n","  datasets_filenames = [f for f in listdir(dataset_path) if isfile(join(dataset_path, f))]\n","  #Sementara dibikin 5 filenames aja dulu\n","  # datasets_filenames = datasets_filenames[:5]\n","  #Sementara dibikin 5 filenames aja dulu\n","else:\n","  print(\"Dataset filenames already exist. Retrieving\")\n","  with open(saved_dataset_path + 'dataset_filenames', 'rb') as f:\n","    datasets_filenames = pickle.load(f)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset filenames already exist. Retrieving\n"]}]},{"cell_type":"code","metadata":{"id":"nS4O4xW_iwGf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968704,"user_tz":-420,"elapsed":32,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"ca4fcdb8-1065-4a2c-b53a-677e5df30758"},"source":["print(len(datasets_filenames))\n","print(datasets_filenames)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["450\n","['art_and_culture-20906350.xml', 'art_and_culture-20927511.xml', 'art_and_culture-20938615.xml', 'art_and_culture-20906382.xml', 'art_and_culture-20918624.xml', 'art_and_culture-20927518.xml', 'art_and_culture-20956483.xml', 'business-20906848.xml', 'art_and_culture-20922011.xml', 'art_and_culture-20906975.xml', 'art_and_culture-20932442.xml', 'art_and_culture-20934732.xml', 'art_and_culture-20922861.xml', 'art_and_culture-20941845.xml', 'art_and_culture-20938179.xml', 'art_and_culture-20924855.xml', 'art_and_culture-20945617.xml', 'art_and_culture-20919723.xml', 'art_and_culture-20900470.xml', 'art_and_culture-20946492.xml', 'art_and_culture-20923803.xml', 'art_and_culture-20943010.xml', 'art_and_culture-20927516.xml', 'art_and_culture-20927491.xml', 'art_and_culture-20927139.xml', 'art_and_culture-20902975.xml', 'art_and_culture-20927486.xml', 'business-20913435.xml', 'art_and_culture-20944018.xml', 'art_and_culture-20925876.xml', 'art_and_culture-20951992.xml', 'art_and_culture-20930055.xml', 'art_and_culture-20917503.xml', 'art_and_culture-20906308.xml', 'art_and_culture-20904497.xml', 'art_and_culture-20920470.xml', 'art_and_culture-20927904.xml', 'business-20914167.xml', 'art_and_culture-20927497.xml', 'art_and_culture-20927391.xml', 'business-20914157.xml', 'business-20925918.xml', 'art_and_culture-20917004.xml', 'art_and_culture-20935692.xml', 'art_and_culture-20914027.xml', 'art_and_culture-20955294.xml', 'art_and_culture-20914080.xml', 'art_and_culture-20937808.xml', 'art_and_culture-20953860.xml', 'business-20938151.xml', 'business-20956841.xml', 'business-20928771.xml', 'business-20950217.xml', 'business-20928803.xml', 'business-20928994.xml', 'business-20928019.xml', 'business-20938839.xml', 'business-20935143.xml', 'business-20943224.xml', 'business-20947478.xml', 'business-20938746.xml', 'business-20930015.xml', 'business-20931091.xml', 'business-20944935.xml', 'business-20948146.xml', 'business-20928735.xml', 'business-20952371.xml', 'business-20938770.xml', 'business-20944113.xml', 'business-20927322.xml', 'business-20952678.xml', 'business-20943676.xml', 'business-20947702.xml', 'business-20939122.xml', 'business-20932660.xml', 'crime-20922463.xml', 'business-20955154.xml', 'business-20943577.xml', 'business-20941809.xml', 'business-20945761.xml', 'business-20932665.xml', 'business-20944228.xml', 'business-20945956.xml', 'business-20926282.xml', 'business-20945578.xml', 'crime-20920852.xml', 'business-20932123.xml', 'business-20934886.xml', 'business-20945104.xml', 'business-20949582.xml', 'business-20935665.xml', 'crime-20956778.xml', 'crime-20951365.xml', 'crime-20925525.xml', 'crime-20949862.xml', 'fashion-20897758.xml', 'crime-20929814.xml', 'crime-20928683.xml', 'crime-20947461.xml', 'crime-20930302.xml', 'fashion-20858793.xml', 'crime-20949287.xml', 'crime-20931041.xml', 'crime-20934875.xml', 'crime-20938183.xml', 'crime-20943028.xml', 'crime-20931384.xml', 'crime-20938244.xml', 'crime-20940936.xml', 'fashion-20898592.xml', 'crime-20938886.xml', 'crime-20945833.xml', 'crime-20937005.xml', 'crime-20941789.xml', 'crime-20938702.xml', 'crime-20939738.xml', 'crime-20955365.xml', 'crime-20943676.xml', 'crime-20955892.xml', 'crime-20943056.xml', 'fashion-20865813.xml', 'crime-20941617.xml', 'crime-20947475.xml', 'crime-20934843.xml', 'crime-20952544.xml', 'fashion-20876523.xml', 'crime-20950837.xml', 'crime-20932877.xml', 'crime-20943227.xml', 'crime-20946675.xml', 'fashion-20872215.xml', 'crime-20934840.xml', 'crime-20955954.xml', 'crime-20933348.xml', 'crime-20948990.xml', 'crime-20932870.xml', 'crime-20932825.xml', 'crime-20944385.xml', 'crime-20943747.xml', 'crime-20943327.xml', 'fashion-20892727.xml', 'fashion-20872365.xml', 'health-20909550.xml', 'health-20929783.xml', 'fashion-20933871.xml', 'health-20914483.xml', 'fashion-20927364.xml', 'fashion-20910434.xml', 'fashion-20948907.xml', 'health-20916374.xml', 'fashion-20943872.xml', 'fashion-20920852.xml', 'fashion-20910063.xml', 'fashion-20947545.xml', 'fashion-20955083.xml', 'fashion-20915970.xml', 'fashion-20915948.xml', 'fashion-20932601.xml', 'health-20924509.xml', 'health-20928811.xml', 'fashion-20901835.xml', 'health-20914472.xml', 'fashion-20941165.xml', 'fashion-20925973.xml', 'fashion-20916437.xml', 'fashion-20921223.xml', 'fashion-20947813.xml', 'fashion-20904195.xml', 'fashion-20933839.xml', 'fashion-20920236.xml', 'fashion-20927531.xml', 'fashion-20902824.xml', 'health-20927405.xml', 'fashion-20918668.xml', 'health-20926124.xml', 'fashion-20904357.xml', 'health-20909967.xml', 'health-20905216.xml', 'fashion-20928732.xml', 'fashion-20953840.xml', 'fashion-20902398.xml', 'health-20922224.xml', 'fashion-20900269.xml', 'fashion-20954019.xml', 'fashion-20928729.xml', 'health-20920255.xml', 'health-20906187.xml', 'fashion-20918972.xml', 'health-20921578.xml', 'fashion-20931214.xml', 'fashion-20947510.xml', 'fashion-20904227.xml', 'fashion-20930058.xml', 'fashion-20915957.xml', 'health-20933028.xml', 'health-20940936.xml', 'health-20954330.xml', 'health-20943541.xml', 'health-20955731.xml', 'health-20937005.xml', 'health-20929814.xml', 'health-20945058.xml', 'health-20945760.xml', 'politics_us-20901993.xml', 'health-20951251.xml', 'politics_us-20812257.xml', 'health-20943862.xml', 'health-20940768.xml', 'health-20943227.xml', 'health-20934873.xml', 'health-20945647.xml', 'health-20932848.xml', 'health-20944348.xml', 'health-20929966.xml', 'politics_us-20862755.xml', 'health-20941742.xml', 'health-20933892.xml', 'politics_us-20891790.xml', 'health-20938183.xml', 'health-20947050.xml', 'health-20933462.xml', 'politics_us-20878146.xml', 'health-20933928.xml', 'politics_us-20812022.xml', 'politics_us-20809566.xml', 'health-20937946.xml', 'health-20931683.xml', 'health-20941613.xml', 'health-20952744.xml', 'politics_us-20886745.xml', 'politics_us-20872626.xml', 'politics_us-20873022.xml', 'health-20933894.xml', 'politics_us-20891350.xml', 'health-20938886.xml', 'politics_us-20905480.xml', 'politics_world-20821011.xml', 'politics_us-20903028.xml', 'politics_world-20831366.xml', 'politics_us-20923817.xml', 'politics_world-20843432.xml', 'politics_world-20834886.xml', 'politics_us-20955150.xml', 'politics_world-20802892.xml', 'politics_us-20919090.xml', 'politics_us-20940595.xml', 'politics_world-20849509.xml', 'politics_world-20853305.xml', 'politics_us-20945376.xml', 'politics_us-20924248.xml', 'politics_us-20948843.xml', 'politics_us-20942508.xml', 'politics_us-20937108.xml', 'politics_us-20944300.xml', 'politics_world-20844814.xml', 'politics_us-20917552.xml', 'politics_us-20929195.xml', 'politics_us-20928019.xml', 'politics_us-20932053.xml', 'politics_world-20874330.xml', 'politics_world-20823321.xml', 'politics_us-20926420.xml', 'politics_us-20935320.xml', 'politics_world-20841273.xml', 'politics_us-20941623.xml', 'politics_us-20916467.xml', 'politics_world-20865957.xml', 'politics_us-20926558.xml', 'politics_us-20945962.xml', 'politics_us-20928611.xml', 'politics_us-20938850.xml', 'politics_us-20929189.xml', 'politics_world-20854093.xml', 'politics_us-20906773.xml', 'politics_world-20810271.xml', 'politics_us-20952164.xml', 'politics_us-20931340.xml', 'politics_us-20925566.xml', 'politics_world-20843189.xml', 'politics_us-20908338.xml', 'politics_us-20940622.xml', 'politics_us-20925694.xml', 'politics_us-20912322.xml', 'politics_us-20933848.xml', 'politics_world-20844722.xml', 'politics_world-20954611.xml', 'politics_world-20925205.xml', 'politics_world-20878252.xml', 'science-20918808.xml', 'politics_world-20927094.xml', 'politics_world-20947475.xml', 'politics_world-20944414.xml', 'politics_world-20945627.xml', 'politics_world-20971758.xml', 'science-20890652.xml', 'politics_world-20887693.xml', 'politics_world-20910780.xml', 'science-20901628.xml', 'politics_world-20946632.xml', 'science-20898196.xml', 'politics_world-20940442.xml', 'politics_world-20947384.xml', 'science-20914304.xml', 'science-20871631.xml', 'politics_world-20933752.xml', 'politics_world-20979458.xml', 'science-20901663.xml', 'science-20870095.xml', 'science-20882930.xml', 'politics_world-20932660.xml', 'politics_world-20889729.xml', 'science-20907100.xml', 'politics_world-20902750.xml', 'politics_world-20884101.xml', 'politics_world-20974900.xml', 'politics_world-20929719.xml', 'science-20902611.xml', 'politics_world-20935440.xml', 'politics_world-20924327.xml', 'politics_world-20945190.xml', 'science-20868924.xml', 'science-20920275.xml', 'science-20914462.xml', 'science-20912151.xml', 'science-20898322.xml', 'science-20908065.xml', 'politics_world-20954266.xml', 'politics_world-20920279.xml', 'politics_world-20904327.xml', 'science-20914461.xml', 'politics_world-20908176.xml', 'science-20890245.xml', 'politics_world-20928045.xml', 'science-20920279.xml', 'science-20860321.xml', 'science-20944183.xml', 'sports-20936979.xml', 'sports-20936162.xml', 'sports-20945906.xml', 'sports-20940241.xml', 'sports-20934852.xml', 'science-20933892.xml', 'science-20947813.xml', 'sports-20937137.xml', 'science-20935792.xml', 'science-20933894.xml', 'sports-20942597.xml', 'science-20927512.xml', 'sports-20940267.xml', 'science-20946412.xml', 'science-20953347.xml', 'sports-20938145.xml', 'science-20928961.xml', 'sports-20936870.xml', 'sports-20935715.xml', 'sports-20945528.xml', 'sports-20935297.xml', 'science-20925092.xml', 'science-20920830.xml', 'sports-20936818.xml', 'science-20927323.xml', 'sports-20944536.xml', 'sports-20941787.xml', 'science-20939222.xml', 'science-20935868.xml', 'science-20939716.xml', 'sports-20939836.xml', 'sports-20941868.xml', 'science-20944755.xml', 'sports-20940173.xml', 'science-20922036.xml', 'sports-20939757.xml', 'science-20940240.xml', 'science-20922037.xml', 'science-20934361.xml', 'science-20955108.xml', 'science-20929394.xml', 'science-20941050.xml', 'science-20933265.xml', 'tech-20925918.xml', 'tech-20938144.xml', 'tech-20929990.xml', 'tech-20932891.xml', 'sports-20949554.xml', 'sports-20951233.xml', 'sports-20947708.xml', 'tech-20936843.xml', 'sports-20956582.xml', 'tech-20928813.xml', 'sports-20954255.xml', 'tech-20935264.xml', 'tech-20927884.xml', 'sports-20955071.xml', 'tech-20932123.xml', 'tech-20929760.xml', 'tech-20923893.xml', 'sports-20951602.xml', 'sports-20951338.xml', 'sports-20955383.xml', 'tech-20933094.xml', 'tech-20928735.xml', 'tech-20919711.xml', 'tech-20943847.xml', 'sports-20947302.xml', 'sports-20956865.xml', 'tech-20931222.xml', 'sports-20956013.xml', 'sports-20954133.xml', 'tech-20921058.xml', 'sports-20950002.xml', 'sports-20953328.xml', 'sports-20950574.xml', 'sports-20951090.xml', 'sports-20955357.xml', 'sports-20949609.xml', 'sports-20948151.xml', 'sports-20949323.xml', 'tech-20943577.xml', 'sports-20954367.xml', 'tech-20927294.xml', 'tech-20942555.xml', 'tech-20932880.xml', 'tech-20925623.xml', 'sports-20954289.xml', 'tech-20916454.xml', 'tech-20931318.xml', 'sports-20954620.xml', 'tech-20927422.xml', 'tech-20937087.xml', 'tech-20932665.xml', 'tech-20931099.xml', 'sports-20952055.xml', 'tech-20955348.xml', 'tech-20953586.xml', 'tech-20949665.xml', 'tech-20946555.xml', 'tech-20952351.xml', 'tech-20948763.xml', 'tech-20947478.xml', 'tech-20945797.xml', 'tech-20954339.xml', 'tech-20948874.xml', 'tech-20950200.xml', 'tech-20944786.xml', 'tech-20946323.xml', 'tech-20949702.xml', 'tech-20946417.xml', 'tech-20944035.xml', 'tech-20949511.xml', 'art_and_culture-20893614.xml']\n"]}]},{"cell_type":"code","metadata":{"id":"0KCJU-29ly2W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968704,"user_tz":-420,"elapsed":28,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"c3562a93-da72-4f3e-b25f-c88489969986"},"source":["if not path.isfile(saved_dataset_path + 'dataset_filenames'):  \n","  with open(saved_dataset_path + 'dataset_filenames', 'wb') as f:\n","    pickle.dump(datasets_filenames, f)\n","else:\n","  print(\"Dataset filenames already exist.\")"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset filenames already exist.\n"]}]},{"cell_type":"markdown","metadata":{"id":"CYbfENFq-I2h"},"source":["## 2.2. Read Dataset"]},{"cell_type":"code","metadata":{"id":"uaVH798w69Kv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968705,"user_tz":-420,"elapsed":23,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"904b1bf5-2b95-4e63-d160-7f9b563f6591"},"source":["if not path.isfile(saved_dataset_path + 'files_paragraphs'):\n","  files = []\n","  # parse an xml file by name\n","  # file = minidom.parse(root+'dataset/train/art_and_culture-20893614.xml')\n","  for i in range(len(datasets_filenames)):\n","    print(i)\n","    files.append(minidom.parse(root+'dataset/train/'+datasets_filenames[i]))\n","  print(\"Jumlah data: \", len(files))\n","else:  \n","  print(\"Dataset files_paragraphs already exist. Retrieving...\")\n","  with open(saved_dataset_path + 'files_paragraphs', 'rb') as f:\n","    files_paragpraphs = pickle.load(f)  "],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset files_paragraphs already exist. Retrieving...\n"]}]},{"cell_type":"code","metadata":{"id":"vXE5NE98XGxm","executionInfo":{"status":"ok","timestamp":1636901968705,"user_tz":-420,"elapsed":21,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def makeListOfSentences(file):\n","  sentencesList = []\n","  sentences = file.getElementsByTagName('sentence')\n","  for sentence in sentences: \n","    eachSentence = \"\"\n","    words = sentence.getElementsByTagName('word')\n","    for i in range(len(words)-1):\n","      if(words[i+1].childNodes[0].data == \".\"):\n","        eachSentence += words[i].childNodes[0].data + words[i+1].childNodes[0].data\n","      elif(i+1 == len(words)-1):\n","        eachSentence += words[i].childNodes[0].data + \" \" + words[i+1].childNodes[0].data + \".\"\n","      else:\n","        eachSentence += words[i].childNodes[0].data + \" \"\n","    sentencesList.append(eachSentence)\n","  return sentencesList"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"higppVq57BLY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968706,"user_tz":-420,"elapsed":22,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"9989e69e-e2be-4a8c-8f75-d30b590eb869"},"source":["if not path.isfile(saved_dataset_path + 'files_paragraphs'):\n","  files_paragpraphs = []\n","  for i in range(len(files)):\n","    print(i)\n","    files_paragpraphs.append(makeListOfSentences(files[i]))\n","  print(len(files_paragpraphs))\n","else:\n","  print(\"Dataset files_paragraphs already exist.\")"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset files_paragraphs already exist.\n"]}]},{"cell_type":"code","metadata":{"id":"m-OwmdBSnn80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968706,"user_tz":-420,"elapsed":20,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"34d8d24c-153e-45d8-a302-4be81f97088b"},"source":["files_paragpraphs[0]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The Tree of Life to premiere in UK.',\n"," \"An insider 's guide to the world of cinema by David Gritten.\",\n"," \"It 's a very British coup -- legendary US director Terrence Malick 's long-awaited new film The Tree of Life , starring Brad Pitt and Sean Penn , is to receive its world premiere not in Cannes next month , but a week earlier in the UK.\",\n"," 'Its distribution company , Icon , has confirmed its May 4 British release date to me.',\n"," 'Speculation about the film has been swirling for more than a year ; at one point , it was expected to be screened in Cannes last year.',\n"," 'This all adds to the mystique that surrounds the elusive Malick.',\n"," \"The film 's American distributor , Fox Searchlight , was clearly taken by surprise by news of the UK opening , describing it as `` not true '' to a Hollywood website.\",\n"," \"My guess is that the film will still be shown in Cannes , though not in competition for the Palme d'Or.\",\n"," 'What do you get when you combine the talents of Johnny Depp , gonzo author-journalist Hunter S Thompson and Bruce Robinson , wayward writerâ€‘director of Withnail and I ?.',\n"," 'A combustible mix , certainly.',\n"," \"Or maybe three good reasons to look forward to the autumn release of Rum Diary , a film based on Thompson 's semi-autobiographical novel , starring Depp and scripted by Robinson , who has also directed ; it 's his first film in nearly 20 years.\",\n"," 'Thompson -LRB- who died in 2005 -RRB- showed Depp the draft of his Rum Diary novel 15 years back , while Depp was shooting another of his works , Fear and Loathing in Las Vegas , and urged him to star in it.',\n"," 'I gather Rum Diary , in which Depp plays a thinly disguised journalist , down on his luck in Puerto Rico , was completed two years ago.',\n"," \"It certainly wo n't be boring.\"]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"LhZZd6pHcy1J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968707,"user_tz":-420,"elapsed":19,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"40977138-8a1e-4f66-b744-18d09da63fe0"},"source":["files_paragpraphs[1]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Penelope Cruz gets Hollywood Walk of Fame star.',\n"," 'Penelope Cruz gets Hollywood Walk of Fame star -LRB- AP -RRB- LOS ANGELES -LRB- AP -RRB- -- Penelope Cruz has been enshrined in concrete.',\n"," 'The Oscar-winning actress unveiled her star on the Hollywood Walk of Fame star Friday , flanked by leading men Javier Bardem and Johnny Depp.',\n"," \"The event is timed ahead of next month 's release of '' `` Pirates of the Caribbean : On Stranger Tides , '' '' in which she stars with Depp.\",\n"," \"The Spanish star says that when she came to the United States in 1994 , she only knew how to say '' `` How are you ? '' ''.\",\n"," \"and '' `` I want to work with Johnny Depp '' '' in English.\",\n"," \"She jokes that now , she knows how to say '' `` I want to work with Johnny Depp again.. '' ''.\",\n"," \"The 36-year-old actress co-starred with husband Bardem in her Oscar-winning role in '' `` Vicky Christina Barcelona.. '' ''.\",\n"," 'They welcomed their son in January.']"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"8sDCI7j4txiC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901968707,"user_tz":-420,"elapsed":16,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"12a8d269-6e7d-4c2e-d7bf-a589c2bc7de7"},"source":["len(files_paragpraphs[0])"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"MGPEJVj1iNBB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901969003,"user_tz":-420,"elapsed":310,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"2751b57c-4c05-4011-cdd2-894e955dd7c9"},"source":["if not path.isfile(saved_dataset_path + 'files_paragraphs'):\n","  with open(saved_dataset_path + 'files_paragraphs', 'wb') as f:\n","    pickle.dump(files_paragpraphs, f)\n","else:\n","  print(\"Dataset files_paragraphs already exist.\")"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset files_paragraphs already exist.\n"]}]},{"cell_type":"markdown","metadata":{"id":"EmALEIpj-Q-6"},"source":["## 2.3 Tokenization"]},{"cell_type":"code","metadata":{"id":"iUbHpOsp84rp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901970695,"user_tz":-420,"elapsed":1711,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"a33d603d-70e9-4b80-ae80-93a86e038a42"},"source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n"]}]},{"cell_type":"markdown","metadata":{"id":"w4_GM5eGCNla"},"source":["Encode until token of words"]},{"cell_type":"code","metadata":{"id":"oFgvLtkeBwfN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901970696,"user_tz":-420,"elapsed":17,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"efc151ee-dd31-461e-f7d1-ac56ab3fc6df"},"source":["if not path.isfile(saved_dataset_path + 'tokenized_files'):\n","  tokenized_files = []\n","  for i in range(len(files_paragpraphs)):\n","    print(i)\n","    tokenized_sentences = []\n","    for sentence in files_paragpraphs[i]:\n","      tokenized_sentences.append(tokenizer.tokenize(sentence))\n","    tokenized_files.append(tokenized_sentences)\n","else:\n","  print(\"Dataset tokenized_files already exist. Retrieving..\")\n","  with open(saved_dataset_path + 'tokenized_files', 'rb') as f:\n","    tokenized_files = pickle.load(f)\n","\n","print(\"Jumlah data: \", len(tokenized_files))"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset tokenized_files already exist. Retrieving..\n","Jumlah data:  450\n"]}]},{"cell_type":"code","metadata":{"id":"UKJDnJfyeTl6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901970696,"user_tz":-420,"elapsed":13,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"d8008fe0-59c5-4b3a-a675-c619a530bf6b"},"source":["print(len(tokenized_files))\n","print(len(tokenized_files[0]))\n","print(len(tokenized_files[0][0]))"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["450\n","14\n","9\n"]}]},{"cell_type":"code","metadata":{"id":"OKBXLUxNe_jJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901970697,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"4df797c1-8d48-45c9-e97b-c4e0fae1a18b"},"source":["print(tokenized_files[0][0])"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['the', 'tree', 'of', 'life', 'to', 'premiere', 'in', 'uk', '.']\n"]}]},{"cell_type":"code","metadata":{"id":"HR2nMGF3rSOA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901970697,"user_tz":-420,"elapsed":7,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"edc588e1-d267-4d0f-9498-6eebff4dc2cd"},"source":["if not path.isfile(saved_dataset_path + 'tokenized_files'):\n","  with open(saved_dataset_path + 'tokenized_files', 'wb') as f:\n","    pickle.dump(tokenized_files, f)\n","else:\n","  print(\"Dataset tokenized_files already exist.\")"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset tokenized_files already exist.\n"]}]},{"cell_type":"markdown","metadata":{"id":"cuvBNHDvBqL2"},"source":["Full Encoded (until number)"]},{"cell_type":"code","metadata":{"id":"vnoiDQG9CDAx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972908,"user_tz":-420,"elapsed":2216,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"dd43036a-1697-4c94-a78e-caeca325d6ba"},"source":["if not (path.isfile(saved_dataset_path + 'files_input_ids') and path.isfile(saved_dataset_path + 'files_attention_masks')):\n","  max_len = 0\n","  for i in range(len(tokenized_files)):\n","    # for j in range(len(tokenized_files[i])):\n","    for sentence in (tokenized_files[i]):\n","      if(len(sentence) > max_len):\n","        max_len = len(sentence)\n","  print(max_len)      \n","else:\n","  print(\"Dataset files_input_ids & files_attention_masks already exist. Retrieving...\")\n","  with open(saved_dataset_path + 'files_input_ids', 'rb') as f:\n","    files_input_ids = pickle.load(f)\n","  with open(saved_dataset_path + 'files_attention_masks', 'rb') as f:\n","    files_attention_masks = pickle.load(f)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset files_input_ids & files_attention_masks already exist. Retrieving...\n"]}]},{"cell_type":"code","metadata":{"id":"oKq7FvvpoyDQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972908,"user_tz":-420,"elapsed":40,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"b5d6ee8c-e731-48a4-b7e3-103cb8ff643b"},"source":["for i in range(len(tokenized_files)):\n","  for j in range(len(tokenized_files[i])):\n","    if(len(tokenized_files[i][j]) == 87):\n","      print(i,j)"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["4 10\n","21 6\n","152 13\n"]}]},{"cell_type":"code","metadata":{"id":"q8YkH44Jpi-b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972909,"user_tz":-420,"elapsed":35,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"e737c57a-115e-4596-947e-d9c6046cd12d"},"source":["len(tokenized_files[4][10])"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["87"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"1hgLIRBar2A8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972910,"user_tz":-420,"elapsed":33,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"e38badfb-a2db-4f23-b3e2-61806eea78e0"},"source":["if not (path.isfile(saved_dataset_path + 'files_input_ids') and path.isfile(saved_dataset_path + 'files_attention_masks')):\n","  files_input_ids = []\n","  files_attention_masks = []\n","\n","  for i in range(len(files_paragpraphs)):\n","    input_ids = []\n","    attention_masks = []\n","    # print(i)\n","  \n","    for sentence in files_paragpraphs[i]:\n","      encoded_dict = tokenizer.encode_plus(\n","                        sentence,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = max_len+2,           # Pad & truncate all sentences.\n","                        padding='max_length',\n","                        truncation = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","      )\n","\n","      input_ids.append(encoded_dict['input_ids'][0])\n","      attention_masks.append(encoded_dict['attention_mask'][0])\n","\n","    files_input_ids.append(input_ids)\n","    files_attention_masks.append(attention_masks)\n","else:\n","  print(\"Dataset files_input_ids & files_attention_masks already exist.\")"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset files_input_ids & files_attention_masks already exist.\n"]}]},{"cell_type":"code","metadata":{"id":"nahLaM0Npo4k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972911,"user_tz":-420,"elapsed":31,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"7d087f60-508f-457f-8df9-d60c2791c8d1"},"source":["np.count_nonzero(files_input_ids[4][10])"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["89"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"MWPZFSAZllJF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972912,"user_tz":-420,"elapsed":27,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"0a69e039-0aaf-4000-82a4-b19cbaee0a7e"},"source":["print(len(files_input_ids))\n","print(len(files_input_ids[0]))\n","print(len(files_input_ids[0][0]))\n","print(np.count_nonzero(files_input_ids[0][0]))"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["450\n","14\n","255\n","11\n"]}]},{"cell_type":"code","metadata":{"id":"bCXDaHe7uA3O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972912,"user_tz":-420,"elapsed":25,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"f8e984ba-6c35-4098-be0a-0859de73d977"},"source":["if not (path.isfile(saved_dataset_path + 'files_input_ids') and path.isfile(saved_dataset_path + 'files_attention_masks')):\n","  with open(saved_dataset_path + 'files_input_ids', 'wb') as f:\n","    pickle.dump(files_input_ids, f)\n","  with open(saved_dataset_path + 'files_attention_masks', 'wb') as f:\n","    pickle.dump(files_attention_masks, f)\n","else:\n","  print(\"Dataset files_input_ids & files_attention_masks already exist.\")"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset files_input_ids & files_attention_masks already exist.\n"]}]},{"cell_type":"markdown","metadata":{"id":"qVYf-JrOI7_B"},"source":["## 2.4. Read Label"]},{"cell_type":"code","metadata":{"id":"p_RpjVnSJWNv","executionInfo":{"status":"ok","timestamp":1636901972913,"user_tz":-420,"elapsed":23,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def read_keywords(filename):\n","  keywords = []\n","\n","  # Opening JSON file\n","  f = open(root+'dataset/label/train.reader.json',)\n","   \n","  # returns JSON object as \n","  # a dictionary\n","  data = json.load(f)\n","   \n","  # Iterating through the json\n","  # list\n","  for keyword in data[filename]:\n","    keywords.append(keyword[0])\n","   \n","  # Closing file\n","  f.close()\n","\n","  return(keywords)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3I60mnty4-c","executionInfo":{"status":"ok","timestamp":1636901972913,"user_tz":-420,"elapsed":22,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def duplicate_keywords(files_input_ids, keywords):\n","  duplicated_keywords = []\n","  for i in range(len(keywords)):\n","    for j in range(len(files_input_ids[i])):\n","      duplicated_keywords.append(keywords[i])\n","  \n","  return duplicated_keywords"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"ztBvseO561rd","executionInfo":{"status":"ok","timestamp":1636901972914,"user_tz":-420,"elapsed":22,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def split_keywords_phrases(keywords):\n","  keyword_phrases_list = []\n","  for i in range(len(keywords)):\n","    keyword_phrases = []\n","    for j in range(len(keywords[i])):\n","      keyword_phrases += keywords[i][j].split(\" \")\n","\n","    keyword_phrases_list.append(keyword_phrases)\n","\n","  return keyword_phrases_list"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"tf_j-r8NJJX8","executionInfo":{"status":"ok","timestamp":1636901972915,"user_tz":-420,"elapsed":22,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def process_label(labels_shape, duplicated_keywords, tokenized_sentences):\n","\n","  labels = [ [ 0 for i in range(labels_shape[1]) ] for j in range(labels_shape[0]) ]\n","\n","  for i in range(len(tokenized_sentences)):\n","    for j in range(len(tokenized_sentences[i])):\n","      if(tokenized_sentences[i][j].lower() in duplicated_keywords[i]):\n","        labels[i][j+1] = 1 #tambah 1 karena ada token awal CLS \n","\n","  return labels"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdGns7c6wAro","executionInfo":{"status":"ok","timestamp":1636901972915,"user_tz":-420,"elapsed":22,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def flatten_data(files_input_ids):\n","  input_ids = []\n","  for each_file_input_ids in files_input_ids:\n","    input_ids += each_file_input_ids\n","  return input_ids"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBbaoB36Fcyd","executionInfo":{"status":"ok","timestamp":1636901972916,"user_tz":-420,"elapsed":22,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def encode_label(labels):\n","  return tf.keras.utils.to_categorical(labels, num_classes=2)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tm8RbvpJM1Vb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901972916,"user_tz":-420,"elapsed":21,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"da91acc0-202d-461e-a46d-d8bd1adc40e5"},"source":["input_ids = flatten_data(files_input_ids)\n","print(len(input_ids))\n","print(len(input_ids[0]))"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["9810\n","255\n"]}]},{"cell_type":"code","metadata":{"id":"HoPlFUVoNybe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973586,"user_tz":-420,"elapsed":686,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"ffc04b87-77b9-41d8-ae42-3f2630b76637"},"source":["tokenized_sentences = flatten_data(tokenized_files)\n","print(len(tokenized_sentences))"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["9810\n"]}]},{"cell_type":"code","metadata":{"id":"wUGUSEhoPutn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973587,"user_tz":-420,"elapsed":29,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"5f4d98e4-bc41-423d-f262-371ba7577e49"},"source":["attention_masks = flatten_data(files_attention_masks)\n","print(len(attention_masks))"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["9810\n"]}]},{"cell_type":"code","metadata":{"id":"cyYCp34WJJbV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973588,"user_tz":-420,"elapsed":27,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"59201c5e-cadf-427f-9916-f050f5818ba9"},"source":["if not path.isfile(saved_dataset_path + 'labels'):\n","  files_keywords = []\n","  for dataset_filename in datasets_filenames:\n","    keywords = read_keywords(dataset_filename[:-4]) #-4 untuk menghilangkan .xml dari filename\n","    files_keywords.append(keywords)\n","  print(len(files_keywords))\n","  print(files_keywords[0])\n","else:\n","  print(\"Dataset labels already exist. Retrieving\")\n","  with open(saved_dataset_path + 'labels', 'rb') as f:\n","    labels = pickle.load(f)"],"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset labels already exist. Retrieving\n"]}]},{"cell_type":"code","metadata":{"id":"KHY8MCW_1KRK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973589,"user_tz":-420,"elapsed":26,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"bdea0138-96e8-4e21-b5ba-cee283e9046d"},"source":["if not path.isfile(saved_dataset_path + 'labels'):\n","  duplicated_keywords = duplicate_keywords(files_input_ids, files_keywords)\n","  print(len(duplicated_keywords))\n","  print(len(duplicated_keywords[0]))\n","else:\n","  print(\"Dataset labels already exist.\")"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset labels already exist.\n"]}]},{"cell_type":"code","metadata":{"id":"83HIPbQE8SzH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973589,"user_tz":-420,"elapsed":24,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"01c60b0e-a07d-428e-d530-4443ab7a5fad"},"source":["if not path.isfile(saved_dataset_path + 'labels'):\n","  phrases_splitted_duplicated_keywords = split_keywords_phrases(duplicated_keywords)\n","  print(len(phrases_splitted_duplicated_keywords))\n","  print(len(phrases_splitted_duplicated_keywords[0]))\n","else:\n","  print(\"Dataset labels already exist.\")"],"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset labels already exist.\n"]}]},{"cell_type":"code","metadata":{"id":"g3HWJJIvYBUP","executionInfo":{"status":"ok","timestamp":1636901973590,"user_tz":-420,"elapsed":23,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["labels_shape = [len(input_ids), len(input_ids[0])]"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"3n3Ru7-W_Kew","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973590,"user_tz":-420,"elapsed":23,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"4c391acc-c751-499a-c28c-6979050a0f18"},"source":["labels_shape"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[9810, 255]"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"mK13EYD6YbQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973593,"user_tz":-420,"elapsed":23,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"ef237c82-28c4-4643-c0ea-59227f3418fb"},"source":["if not path.isfile(saved_dataset_path + 'labels'):\n","  labels = process_label(labels_shape, phrases_splitted_duplicated_keywords, tokenized_sentences)\n","  print(labels[-1])\n","else:\n","  print(\"Dataset labels already exist.\")\n"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset labels already exist.\n"]}]},{"cell_type":"code","metadata":{"id":"zhggqLNhv8yj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973593,"user_tz":-420,"elapsed":21,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"576e2468-7e3d-4318-dced-e96b323e181c"},"source":["if not path.isfile(saved_dataset_path + 'labels'):\n","  with open(saved_dataset_path + 'labels', 'wb') as f:\n","    pickle.dump(labels, f)\n","else:\n","  print(\"Dataset labels already exist.\")"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset labels already exist.\n"]}]},{"cell_type":"markdown","metadata":{"id":"oNihQkTDKK-q"},"source":["## 3.4. Training & Validation Split"]},{"cell_type":"code","metadata":{"id":"OVdv_NqpwllD","executionInfo":{"status":"ok","timestamp":1636901973594,"user_tz":-420,"elapsed":20,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["with open(saved_dataset_path + 'labels', 'rb') as f:\n","  labels = pickle.load(f)  "],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"W7UcGGYdTpkv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901973595,"user_tz":-420,"elapsed":20,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"d4d98151-e477-4136-b8fb-7ec0fe3546e1"},"source":["input_ids = torch.stack(input_ids)\n","input_ids.shape"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([9810, 255])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"Aeu0IaVgTxhE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901974087,"user_tz":-420,"elapsed":509,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"b1ea3ee4-d3df-415a-a8eb-8e6ef98d8f5c"},"source":["attention_masks = torch.stack(attention_masks)\n","attention_masks.shape"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([9810, 255])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"oRPleXeINgpK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901974088,"user_tz":-420,"elapsed":9,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"ee23b5e6-86d2-4af2-d642-480108f28dd8"},"source":["labels = torch.tensor(labels)\n","labels.shape"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([9810, 255])"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"v_dsSrHxKNha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901974088,"user_tz":-420,"elapsed":6,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"4f9e13b1-954d-4e67-c6f1-da8c881dced7"},"source":["# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["8,829 training samples\n","  981 validation samples\n"]}]},{"cell_type":"code","metadata":{"id":"XGUqOCtgqGhP","executionInfo":{"status":"ok","timestamp":1636901974088,"user_tz":-420,"elapsed":4,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"90ljm0EAaW3D"},"source":["# 3. Model"]},{"cell_type":"code","metadata":{"id":"UuK20FgZasBc","executionInfo":{"status":"ok","timestamp":1636901974089,"user_tz":-420,"elapsed":4,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["model_checkpoint = \"distilbert-base-uncased\""],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmpH7ZWrasDu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636901975513,"user_tz":-420,"elapsed":1428,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"6a7c2b08-c025-44bd-9975-455979d58f70"},"source":["model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint, \n","    num_labels=2, \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","model.cuda()"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["DistilBertForTokenClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"4CI0y8z9drX2"},"source":["## 3.1. Predict (Test Shape)"]},{"cell_type":"code","metadata":{"id":"PIglT304qhx6","executionInfo":{"status":"ok","timestamp":1636901975513,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# def get_list_of_keywords(tokenized_sentences, prediction):\n","#   keywords=[]\n","#   for i in range(len(tokenized_sentences)):\n","#     for j in range(len(tokenized_sentences[i])):\n","#       if(prediction[i][j+1]==1): #+1 karena ada token CLS di awal sentence\n","#         keywords.append(tokenized_sentences[i][j])\n","#   return keywords"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"j6z7jTCnz10R","executionInfo":{"status":"ok","timestamp":1636901975514,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# num_sentences = len(tokenized_files[0]) #file pertama\n","# num_sentences"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"MV-StbfI2SHa","executionInfo":{"status":"ok","timestamp":1636901975514,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# len(tokenized_sentences[0])"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3deWY7Ydxbu","executionInfo":{"status":"ok","timestamp":1636901975515,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# prediction = model(input_ids[:num_sentences].to(device), attention_mask=attention_masks[:num_sentences].to(device))\n","# prediction"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"ylXUpG03eHk_","executionInfo":{"status":"ok","timestamp":1636901975515,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# final_prediction = prediction[0].detach().to('cpu').numpy()\n","# final_prediction.shape"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewsmqiw-rqMJ","executionInfo":{"status":"ok","timestamp":1636901975515,"user_tz":-420,"elapsed":9,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# prediction_temp = np.argmax(final_prediction[:], axis=2)\n","# prediction_temp.shape"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjoOVagt5i-K","executionInfo":{"status":"ok","timestamp":1636901975516,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# files_keywords[0]"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"43vYPjJZ3Tf5","executionInfo":{"status":"ok","timestamp":1636901975516,"user_tz":-420,"elapsed":9,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# get_list_of_keywords(tokenized_sentences[:num_sentences], prediction_temp)"],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qR-uPgJldelw"},"source":["## 3.1 Optimizer & Learning Rate Scheduler"]},{"cell_type":"code","metadata":{"id":"OMq1W0PdasG5","executionInfo":{"status":"ok","timestamp":1636901975517,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"N884DVwpdWKx","executionInfo":{"status":"ok","timestamp":1636901975518,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 2\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q3f3rFP0diNW"},"source":["## Training Loop"]},{"cell_type":"code","metadata":{"id":"DvqJ3lRiJngK","executionInfo":{"status":"ok","timestamp":1636901975518,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=2).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpt6tR83keZD","executionInfo":{"status":"ok","timestamp":1636901975519,"user_tz":-420,"elapsed":11,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"6J-FYdx6nFE_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636902694608,"user_tz":-420,"elapsed":719099,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"7518756e-d4c5-41ab-c935-54f091dde06a"},"source":["# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # In PyTorch, calling `model` will in turn call the model's `forward` \n","        # function and pass down the arguments. The `forward` function is \n","        # documented here: \n","        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n","        # The results are returned in a results object, documented here:\n","        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n","        # Specifically, we'll get the loss (because we provided labels) and the\n","        # \"logits\"--the model outputs prior to activation.\n","        result = model(b_input_ids,\n","                       attention_mask=b_input_mask, \n","                       labels=b_labels,\n","                       return_dict=True)\n","\n","        loss = result.loss\n","        logits = result.logits\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            result = model(b_input_ids,\n","                           attention_mask=b_input_mask,\n","                           labels=b_labels,\n","                           return_dict=True)\n","\n","        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n","        # output values prior to applying an activation function like the \n","        # softmax.\n","        loss = result.loss\n","        logits = result.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","  Batch    40  of    276.    Elapsed: 0:00:50.\n","  Batch    80  of    276.    Elapsed: 0:01:40.\n","  Batch   120  of    276.    Elapsed: 0:02:30.\n","  Batch   160  of    276.    Elapsed: 0:03:20.\n","  Batch   200  of    276.    Elapsed: 0:04:10.\n","  Batch   240  of    276.    Elapsed: 0:05:00.\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:05:45\n","\n","Running Validation...\n","  Accuracy: 0.98\n","  Validation Loss: 0.27\n","  Validation took: 0:00:15\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","  Batch    40  of    276.    Elapsed: 0:00:50.\n","  Batch    80  of    276.    Elapsed: 0:01:40.\n","  Batch   120  of    276.    Elapsed: 0:02:30.\n","  Batch   160  of    276.    Elapsed: 0:03:20.\n","  Batch   200  of    276.    Elapsed: 0:04:10.\n","  Batch   240  of    276.    Elapsed: 0:05:00.\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:05:45\n","\n","Running Validation...\n","  Accuracy: 0.97\n","  Validation Loss: 0.27\n","  Validation took: 0:00:15\n","\n","Training complete!\n","Total training took 0:11:59 (h:mm:ss)\n"]}]},{"cell_type":"code","metadata":{"id":"6O_NbXFGMukX","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1636902694611,"user_tz":-420,"elapsed":56,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"89bebe3b-a75c-41a3-a68e-1d981ccc221e"},"source":["# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.30</td>\n","      <td>0.27</td>\n","      <td>0.98</td>\n","      <td>0:05:45</td>\n","      <td>0:00:15</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.26</td>\n","      <td>0.27</td>\n","      <td>0.97</td>\n","      <td>0:05:45</td>\n","      <td>0:00:15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               0.30         0.27           0.98       0:05:45         0:00:15\n","2               0.26         0.27           0.97       0:05:45         0:00:15"]},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"cSdsLRz4exoJ"},"source":["# 4. Save Module"]},{"cell_type":"code","metadata":{"id":"6ulTWaOr8QNY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636902695128,"user_tz":-420,"elapsed":540,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"0e918ad3-890b-47e8-eee3-92d07124bb8b"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = './saved_model/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"],"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to ./saved_model/\n"]},{"output_type":"execute_result","data":{"text/plain":["('./saved_model/tokenizer_config.json',\n"," './saved_model/special_tokens_map.json',\n"," './saved_model/vocab.txt',\n"," './saved_model/added_tokens.json')"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"NxlZsafTC-V5","executionInfo":{"status":"ok","timestamp":1636902699405,"user_tz":-420,"elapsed":4291,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["# Copy the model files to a directory in your Google Drive.\n","!cp -r ./saved_model/ \"drive/MyDrive/NLP/Tugas Akhir/keyword extraction resources/\""],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgPO12y5hFe3","executionInfo":{"status":"ok","timestamp":1636902699407,"user_tz":-420,"elapsed":10,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}}},"source":["config_class, model_class, tokenizer_class = (BertConfig, AutoModelForTokenClassification, BertTokenizer)"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"nskPzUM084zL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636902700534,"user_tz":-420,"elapsed":1134,"user":{"displayName":"Rifaldy Aristya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13364895832625027797"}},"outputId":"4c3855e0-939a-4033-966c-dde23f89bdbd"},"source":["# Load a trained model and vocabulary that you have fine-tuned\n","model = model_class.from_pretrained(output_dir)\n","tokenizer = tokenizer_class.from_pretrained(output_dir)\n","\n","# Copy the model to the GPU.\n","model.to(device)"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DistilBertForTokenClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":72}]}]}